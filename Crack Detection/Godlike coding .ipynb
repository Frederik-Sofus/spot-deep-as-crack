{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(img, binary):\n",
    "    \n",
    "    pixel_is = img[binary == 255]\n",
    "    \n",
    "    mean_i = pixel_is.mean()\n",
    "    std_i = pixel_is.std()\n",
    "\n",
    "    gauss = cv2.GaussianBlur(img, (5,5), 0)\n",
    "    lap = cv2.Laplacian(gauss, cv2.CV_64F)\n",
    "    \n",
    "    pixel_gs = lap[binary == 255]\n",
    "    \n",
    "    mean_g = pixel_gs.mean()\n",
    "    std_g = pixel_gs.std()\n",
    "          \n",
    "    mag, ori = gradients(img)\n",
    "            \n",
    "# gauss_pos = [cv2.GaussianBlur(pos[i], (5,5), 0) for i in range(SAMPLE_SIZE)]\n",
    "# gauss_neg = [cv2.GaussianBlur(neg[i], (5,5), 0) for i in range(SAMPLE_SIZE)]\n",
    "\n",
    "# lap_pos = [cv2.Laplacian(gauss_pos[i], cv2.CV_64F) for i in range(SAMPLE_SIZE)]\n",
    "# lap_neg = [cv2.Laplacian(gauss_neg[i], cv2.CV_64F) for i in range(SAMPLE_SIZE)]\n",
    "    return mean_i, std_i, mean_g, std_g, mag, ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' First Pipeline : Greyscale -> Median Blur -> Otsu's Method + Inverse Threshold Binarization -> Erosion/Dilation  '''\n",
    "\n",
    "def pip1(img, blurKernel=3, e_it=1, e_kern=5, d_it=1, d_kern=3):\n",
    "    '''\n",
    "    blurKernel: Size of median kernel (3x3, 5x5 ...)\n",
    "    e_it: Number of erosion iterations \n",
    "    e_kern: Kernel size of erosion\n",
    "    d_it: Number of dilation iterations\n",
    "    d_kern: Kernel size of dilation\n",
    "    '''\n",
    "    \n",
    "    # Linear Greyscale conversion (Y = 0.299*R + 0.587*G +0.114*B)\n",
    "    g_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Applies a median blur (blurKernek x blurKernel)\n",
    "    blur = cv2.medianBlur(g_img, blurKernel)\n",
    "    \n",
    "    # Otsu's method finds dynamic threshold value, pixels are assigned either 0 or 255\n",
    "    th_val, img_bin = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Erosion and Dilation\n",
    "    kernel = cv2.getStructuringElement(cv2.cv2.MORPH_ELLIPSE, (e_kern,e_kern))\n",
    "    ero = cv2.erode(img_bin, kernel, iterations=e_it)\n",
    "    kernel = cv2.getStructuringElement(cv2.cv2.MORPH_ELLIPSE, (d_kern,d_kern))\n",
    "    dil = cv2.dilate(ero, kernel, iterations=d_it)\n",
    "    \n",
    "    return dil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Second Pipeline : Greyscale -> Median Blur -> Morphological Transformation (Opening)  \n",
    "    -> Otsu's Method + Inverse Threshold Binarization -> Erosion/Dilation '''\n",
    "\n",
    "def pip2(img, blurKernel=3, open_k=5, open_its=(3, 1), e_it=2, e_kern=7, d_it=1, d_kern=3):\n",
    "    '''\n",
    "    blurKernel: Size of median kernel (3x3, 5x5 ...)\n",
    "    e_it: Number of erosion iterations \n",
    "    e_kern: Kernel size of erosion\n",
    "    d_it: Number of dilation iterations\n",
    "    d_kern: Kernel size of dilation\n",
    "    '''\n",
    "    \n",
    "    # Linear Greyscale conversion (Y = 0.299*R + 0.587*G +0.114*B)\n",
    "    g_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Applies a median blur (blurKernek x blurKernel)\n",
    "    blur = cv2.medianBlur(g_img, blurKernel)\n",
    "    \n",
    "    # Opening (Erosion -> Dilation) on greyscale. \n",
    "    kernel = cv2.getStructuringElement(cv2.cv2.MORPH_ELLIPSE, (open_k,open_k))\n",
    "    erosion = cv2.erode(blur, kernel, iterations = open_its[0])\n",
    "    dilation = cv2.dilate(erosion, kernel, iterations = open_its[1])\n",
    "     \n",
    "    # Otsu's method finds dynamic threshold value, pixels are assigned either 0 or 255\n",
    "    th_val, img_bin = cv2.threshold(dilation, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Erosion and Dilation\n",
    "    kernel = cv2.getStructuringElement(cv2.cv2.MORPH_ELLIPSE, (e_kern,e_kern))\n",
    "    ero = cv2.erode(img_bin, kernel, iterations=e_it)\n",
    "    kernel = cv2.getStructuringElement(cv2.cv2.MORPH_ELLIPSE, (d_kern,d_kern))\n",
    "    dil = cv2.dilate(ero, kernel, iterations=d_it)\n",
    "    \n",
    "    return dil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Third Pipeline : Greyscale -> Median Blur -> Non-Linear Greyscale Transformation -> \n",
    "    Improved Otsu's Method + Inverse Threshold Binarization -> Erosion/Dilation '''\n",
    "\n",
    "def pip3(img, blurKernel=3, open_k=5, open_its=(3, 1), e_it=1, e_kern=5, d_it=1, d_kern=5):\n",
    "    '''\n",
    "    blurKernel: Size of median kernel (3x3, 5x5 ...)\n",
    "    e_it: Number of erosion iterations \n",
    "    e_kern: Kernel size of erosion\n",
    "    d_it: Number of dilation iterations\n",
    "    d_kern: Kernel size of dilation\n",
    "    '''\n",
    "    \n",
    "    # Linear Greyscale conversion (Y = 0.299*R + 0.587*G +0.114*B)\n",
    "    g_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Applies a median blur (blurKernek x blurKernel)\n",
    "    blur = cv2.medianBlur(g_img, blurKernel)\n",
    "    \n",
    "    # Opening (Erosion -> Dilation) on greyscale. \n",
    "    kernel = cv2.getStructuringElement(cv2.cv2.MORPH_ELLIPSE, (open_k,open_k))\n",
    "    erosion = cv2.erode(blur, kernel, iterations = 1)\n",
    "    dilation = cv2.dilate(erosion, kernel, iterations = 1)\n",
    "     \n",
    "    # Otsu's method finds dynamic threshold value, pixels are assigned either 0 or 255\n",
    "    th_val, img_bin = cv2.threshold(dilation, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "    # Dynamically calculation Upper bound for the Non-linear threshold\n",
    "    ub_lim = round(np.count_nonzero(img_bin)/(227*227), 4)\n",
    "    \n",
    "    # Non Linear Greyscale\n",
    "    nl = nl_grayscale(blur, 0.02, ub_lim)\n",
    "\n",
    "    # Improved Otsu's\n",
    "    th_val, img_bin = cv2.threshold(dilation, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)    \n",
    "    imp_otsu = improved_otsu(nl, th_val)\n",
    "    \n",
    "    # Erosion and Dilation\n",
    "    kernel = cv2.getStructuringElement(cv2.cv2.MORPH_ELLIPSE, (e_kern,e_kern))\n",
    "    ero = cv2.erode(imp_otsu, kernel, iterations=e_it)\n",
    "    kernel = cv2.getStructuringElement(cv2.cv2.MORPH_ELLIPSE, (d_kern,d_kern))\n",
    "    out = cv2.dilate(ero, kernel, iterations=d_it)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Fourth Pipeline : Greyscale -> Median Blur -> Non-Linear Greyscale Transformation -> \n",
    "    Otsu's Method on grey pixels only (no 0 or 255) + Inverse Threshold Binarization -> Erosion/Dilation '''\n",
    "\n",
    "def pip4(img, blurKernel=3, open_k=5, open_its=(3, 1), e_it=1, e_kern=5, d_it=1, d_kern=5):\n",
    "    '''\n",
    "    blurKernel: Size of median kernel (3x3, 5x5 ...)\n",
    "    e_it: Number of erosion iterations \n",
    "    e_kern: Kernel size of erosion\n",
    "    d_it: Number of dilation iterations\n",
    "    d_kern: Kernel size of dilation\n",
    "    '''\n",
    "    \n",
    "    # Linear Greyscale conversion (Y = 0.299*R + 0.587*G +0.114*B)\n",
    "    g_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Applies a median blur (blurKernek x blurKernel)\n",
    "    blur = cv2.medianBlur(g_img, blurKernel)\n",
    "    \n",
    "    # Opening (Erosion -> Dilation) on greyscale. \n",
    "    kernel = cv2.getStructuringElement(cv2.cv2.MORPH_ELLIPSE, (open_k,open_k))\n",
    "    erosion = cv2.erode(blur, kernel, iterations = 1)\n",
    "    dilation = cv2.dilate(erosion, kernel, iterations = 1)\n",
    "     \n",
    "    # Otsu's method finds dynamic threshold value, pixels are assigned either 0 or 255\n",
    "    th_val, img_bin = cv2.threshold(dilation, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    ub_lim = round(np.count_nonzero(img_bin)/(227*227), 4)\n",
    "    \n",
    "    # Non Linear Greyscale\n",
    "    nl = nl_grayscale(blur, 0.02, ub_lim)\n",
    "    nl_grey = nl[nl != 0]\n",
    "    nl_grey = nl_grey[nl_grey != 255]\n",
    "\n",
    "    #\n",
    "    th_val, img_bin = cv2.threshold(nl_grey, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)    \n",
    "    th_val, img_bin = cv2.threshold(nl, th_val, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    \n",
    "    # Erosion and Dilation\n",
    "    kernel = cv2.getStructuringElement(cv2.cv2.MORPH_ELLIPSE, (e_kern,e_kern))\n",
    "    ero = cv2.erode(img_bin, kernel, iterations=e_it)\n",
    "    kernel = cv2.getStructuringElement(cv2.cv2.MORPH_ELLIPSE, (d_kern,d_kern))\n",
    "    out = cv2.dilate(ero, kernel, iterations=d_it)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rasmus\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\core\\_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "C:\\Users\\Rasmus\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\core\\_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "C:\\Users\\Rasmus\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\core\\_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 1\n",
      "Crack -> (Mean, Std Dev) (93.55024364546293, 24.105391507683432, 1.457570569384082, 4.111231346696771, 37, 40)\n",
      "No Crack -> (Mean, Std Dev)  (192.5274370411672, 7.8270298673465915, 0.7887278134002416, 2.6008989725584093, 36, 40) \n",
      "Pipeline 2\n",
      "Crack -> (Mean, Std Dev) (99.07701123080449, 27.762191469126, 1.1011154404461763, 4.569383221343808, 37, 40)\n",
      "No Crack -> (Mean, Std Dev)  (191.05830343877957, 9.693470609620638, 0.4963220639924629, 3.2252630701327227, 36, 40) \n",
      "Pipeline 3\n",
      "Crack -> (Mean, Std Dev) (96.81588205067393, 25.424797890724378, 1.4454721530495276, 4.165436929095721, 37, 40)\n",
      "No Crack -> (Mean, Std Dev)  (193.0990550466287, 7.710651314727455, 0.7972889329041842, 2.5949786921914755, 36, 40) \n",
      "Pipeline 4\n",
      "Crack -> (Mean, Std Dev) (80.86816968675376, 18.07695609876684, 1.831015592077539, 4.004382199857822, 37, 40)\n",
      "No Crack -> (Mean, Std Dev)  (186.2163947845407, 7.741270658533134, 1.2665614219727532, 2.897937886980571, 36, 40) \n"
     ]
    }
   ],
   "source": [
    "img_pos = cv2.imread(\"C:\\\\Users\\\\Rasmus\\\\Desktop\\\\Deep Learning\\\\concrete_data\\\\Positive\\\\{0:05d}.jpg\".format(np.random.randint(1,10000)))\n",
    "img_neg = cv2.imread(\"C:\\\\Users\\\\Rasmus\\\\Desktop\\\\Deep Learning\\\\concrete_data\\\\Negative\\\\{0:05d}.jpg\".format(np.random.randint(1,20000)))\n",
    "\n",
    "# img_pos = cv2.imread(\"C:\\\\Users\\\\Rasmus\\\\Desktop\\\\Deep Learning\\\\concrete_data\\\\Positive\\\\{0:05d}.jpg\".format(6659))\n",
    "# img_neg = cv2.imread(\"C:\\\\Users\\\\Rasmus\\\\Desktop\\\\Deep Learning\\\\concrete_data\\\\Negative\\\\{0:05d}.jpg\".format(np.random.randint(1,20000)))\n",
    "\n",
    "crack1 = pip1(img_pos)\n",
    "no_crack1 = pip1(img_neg)\n",
    "\n",
    "crack2 = pip2(img_pos)\n",
    "no_crack2 = pip2(img_neg)\n",
    "\n",
    "crack3 = pip3(img_pos)\n",
    "no_crack3 = pip3(img_neg)\n",
    "\n",
    "crack4 = pip4(img_pos)\n",
    "no_crack4 = pip4(img_neg)\n",
    "\n",
    "cv2.imshow(\"Raw Crack\", img_pos)\n",
    "cv2.imshow(\"Raw No Crack\", img_neg)\n",
    "\n",
    "cv2.imshow(\"Pipeline1 Crack\", crack1)\n",
    "cv2.imshow(\"Pipeline1 No Crack\", no_crack1)\n",
    "\n",
    "cv2.imshow(\"Pipeline2 Crack\", crack2)\n",
    "cv2.imshow(\"Pipeline2 No Crack\", no_crack2)\n",
    "\n",
    "cv2.imshow(\"Pipeline3 Crack\", crack3)\n",
    "cv2.imshow(\"Pipeline3 No Crack\", no_crack3)\n",
    "\n",
    "cv2.imshow(\"Pipeline4 Crack\", crack4)\n",
    "cv2.imshow(\"Pipeline4 No Crack\", no_crack4)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Pipeline 1\")\n",
    "print(\"Crack -> (Mean, Std Dev) {}\".format(feature_extraction(img_pos, crack1)))\n",
    "print(\"No Crack -> (Mean, Std Dev)  {} \".format(feature_extraction(img_neg, no_crack1)))\n",
    "\n",
    "\n",
    "print(\"Pipeline 2\")\n",
    "print(\"Crack -> (Mean, Std Dev) {}\".format(feature_extraction(img_pos, crack2)))\n",
    "print(\"No Crack -> (Mean, Std Dev)  {} \".format(feature_extraction(img_neg, no_crack2)))\n",
    "\n",
    "print(\"Pipeline 3\")\n",
    "print(\"Crack -> (Mean, Std Dev) {}\".format(feature_extraction(img_pos, crack3)))\n",
    "print(\"No Crack -> (Mean, Std Dev)  {} \".format(feature_extraction(img_neg, no_crack3)))\n",
    "\n",
    "print(\"Pipeline 4\")\n",
    "print(\"Crack -> (Mean, Std Dev) {}\".format(feature_extraction(img_pos, crack4)))\n",
    "print(\"No Crack -> (Mean, Std Dev)  {} \".format(feature_extraction(img_neg, no_crack4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_limits(img, lb, ub):\n",
    "    w, h = img.shape\n",
    "    im_arr = np.reshape(img, (w*h))\n",
    "    \n",
    "    im_arr = np.sort(im_arr)\n",
    "    \n",
    "    i_a = int(round(w*h * lb, 0))\n",
    "    i_b = int(round(w*h * ub, 0))\n",
    "    \n",
    "    a = im_arr[i_a-1]\n",
    "    b = im_arr[i_b-1]\n",
    "    \n",
    "    t = find_t(im_arr, i_a, i_b)\n",
    "    \n",
    "    return a, b, t\n",
    "\n",
    "def find_t(arr, ia, ib):\n",
    "    a, b = arr[ia], arr[ib]\n",
    "    \n",
    "    interval = arr[ia:ib+1]\n",
    "    mean_i = interval.mean()\n",
    "    \n",
    "    t = (2*mean_i*(b - a)) / (255*(a+b))\n",
    "    return t\n",
    "\n",
    "def nl_grayscale(img, lb, ub):\n",
    "    '''\n",
    "    Non-Linear Greyscale Transformation\n",
    "    \n",
    "    Need's fixing: Upper Bound (ub) values .. if above 1.0 or below 0.02 it will mess up\n",
    "    '''\n",
    "    new_a = 0\n",
    "    new_b = 255\n",
    "    a, b, t = find_limits(img, lb, ub)\n",
    "    w, h = img.shape\n",
    "    \n",
    "\n",
    "    im_out = img.copy()\n",
    "    \n",
    "    i = img<a\n",
    "    im_out[i] = new_a\n",
    "    \n",
    "    i = img > b\n",
    "    im_out[i] = new_b\n",
    "    \n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            if img[i, j] < a and not img[i, j] > b:\n",
    "                new_a + ((new_a - new_b) / (a**t - b**t)) * (img[i, j]**t - a**t)\n",
    "                \n",
    "    \n",
    "    return im_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_otsu(img, thresh, ksize=7):\n",
    "\n",
    "    w, h = img.shape\n",
    "    x = ksize // 2\n",
    "    y = ksize // 2\n",
    "    im_out = img.copy()\n",
    "    \n",
    "    # STEP 1 -> 3\n",
    "    \n",
    "    while not x > w:\n",
    "        while y < (h - ksize // 2):\n",
    "            \n",
    "            if not x == w:\n",
    "                window = img[(x-3):(x+4),(y-3):(y+4)]\n",
    "            else:\n",
    "                window = img[(x-3):x,(y-3):(y+4)]\n",
    "                \n",
    "            var = window.std()\n",
    "            \n",
    "\n",
    "            if var < thresh:\n",
    "                new_thresh, seg_window = cv2.threshold(window, thresh, 255, cv2.THRESH_BINARY_INV)\n",
    "            else:\n",
    "                new_thresh, seg_window = cv2.threshold(window, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "                \n",
    "                \n",
    "            if not x == w:\n",
    "                im_out[(x-3):(x+4),(y-3):(y+4)] = seg_window\n",
    "            else:\n",
    "                im_out[(x-3):x,(y-3):(y+4)] = seg_window\n",
    "                \n",
    "            y += ksize\n",
    "            \n",
    "        if not x == w:\n",
    "            window = img[(x-3):(x+4),(y-3):y]\n",
    "        else:\n",
    "            window = img[(x-3):x,(y-3):y]\n",
    "            \n",
    "        var = window.std()\n",
    "        \n",
    "        if var < thresh:\n",
    "            new_thresh, seg_window = cv2.threshold(window, thresh, 255, cv2.THRESH_BINARY_INV)\n",
    "        else:\n",
    "            new_thresh, seg_window = cv2.threshold(window, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        if not x == w:\n",
    "            im_out[(x-3):(x+4),(y-3):y] = seg_window\n",
    "        else:\n",
    "            im_out[(x-3):x,(y-3):y] = seg_window\n",
    "            \n",
    "        x += ksize\n",
    "        y = ksize // 2\n",
    "    \n",
    "    \n",
    "\n",
    "            \n",
    "    window = img[(x-3):x,(y-3):(y+4)]\n",
    "    var = window.std()\n",
    "    if var < thresh:\n",
    "        new_thresh, seg_window = cv2.threshold(window, thresh, 255, cv2.THRESH_BINARY_INV)\n",
    "    else:\n",
    "        new_thresh, seg_window = cv2.threshold(window, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    im_out[(x-3):x,(y-3):(y+4)] = seg_window\n",
    "    \n",
    "    return im_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(img):\n",
    "    number_bins = 40\n",
    "\n",
    "    ############ POSITIVE IMAGES ############################\n",
    "    # Calculating the gradients\n",
    "    sobelX_pos = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=1)\n",
    "    sobelY_pos = cv2.Sobel(img, cv2.CV_32F, 0, 1, ksize=1)\n",
    "\n",
    "    # Using vector tool to find the magnitudes and the angles\n",
    "    mag, angle = cv2.cartToPolar(sobelX_pos, sobelY_pos, angleInDegrees=True)\n",
    "\n",
    "    # Making the histograms\n",
    "    hist_mag = np.histogram(mag, bins=number_bins)\n",
    "    hist_angle = np.histogram(angle, bins=number_bins)\n",
    "    \n",
    "    \n",
    "    # This Is the Version where we compress the values into bins\n",
    "    un_mag = len(np.unique(hist_mag[0]))\n",
    "    un_angle = len(np.unique(hist_angle[0]))\n",
    "    \n",
    "    # This is the version where we do not compress values into bins\n",
    "#     un_mag = len(np.unique(mag))\n",
    "#     un_angle = len(np.unique(angle))\n",
    "    \n",
    "    return un_mag, un_angle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
